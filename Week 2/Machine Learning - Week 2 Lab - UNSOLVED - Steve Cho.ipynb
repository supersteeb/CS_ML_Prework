{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 2 Lab: Classification, Parameter & Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this week's lab, we'll be focusing on implementing the following new supervised learning estimators:\n",
    "* Support Vector Machines\n",
    "* Random Forest Classifiers\n",
    "\n",
    "In addition, we'll look at techniques to optimize both the **parameter** values for our estimators, as well the **features** that we decide to use with them. We'll explore these concepts by using the following Python functions:\n",
    "* GridSearchCV\n",
    "* SelectFromModel\n",
    "* RFE (Recursive Feature Elimination)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries\n",
    "\n",
    "Import the usual libraries, `pandas` as `pd` and `numpy` as `np`, and `matplotlib.pyplot` as `plt`. (Remember to also\n",
    "`%matplotlib inline`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the Data\n",
    "\n",
    "We'll use the built in breast cancer dataset from Scikit Learn: `load_breast_cancer`. We can `import` it `from sklearn.datasets`. The dataset can be loaded by calling `load_breast_cancer()`. Save it in a variable called `cancer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer \n",
    "\n",
    "cancer = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have worked with dataframes up until now, but this data set is presented in a dictionary form. Print out it's `keys`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\n",
      "target\n",
      "target_names\n",
      "DESCR\n",
      "feature_names\n"
     ]
    }
   ],
   "source": [
    "for key in cancer:\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can grab information and arrays out of this dictionary to set up our data frame and understanding of the features. The feature data is stored in `'data'`, the feature names are stored in `'feature_names'`, and the labels are stored in `target`. Print the `'feature_names'` to see them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mean radius' 'mean texture' 'mean perimeter' 'mean area'\n",
      " 'mean smoothness' 'mean compactness' 'mean concavity'\n",
      " 'mean concave points' 'mean symmetry' 'mean fractal dimension'\n",
      " 'radius error' 'texture error' 'perimeter error' 'area error'\n",
      " 'smoothness error' 'compactness error' 'concavity error'\n",
      " 'concave points error' 'symmetry error' 'fractal dimension error'\n",
      " 'worst radius' 'worst texture' 'worst perimeter' 'worst area'\n",
      " 'worst smoothness' 'worst compactness' 'worst concavity'\n",
      " 'worst concave points' 'worst symmetry' 'worst fractal dimension']\n"
     ]
    }
   ],
   "source": [
    "print(cancer['feature_names'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up DataFrame\n",
    "\n",
    "Now let's set up our dataset into a pandas dataframe. The `'data'` key from the `cancer` dictionary will be our feature data for our dataframe, and `'feature_names'` will be the columns. Store these features in `df_feat`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feat = pd.DataFrame(cancer['data'], columns=(cancer['feature_names']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print out the `head` of `df_feat`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   mean fractal dimension           ...             worst radius  \\\n",
       "0                 0.07871           ...                    25.38   \n",
       "1                 0.05667           ...                    24.99   \n",
       "2                 0.05999           ...                    23.57   \n",
       "3                 0.09744           ...                    14.91   \n",
       "4                 0.05883           ...                    22.54   \n",
       "\n",
       "   worst texture  worst perimeter  worst area  worst smoothness  \\\n",
       "0          17.33           184.60      2019.0            0.1622   \n",
       "1          23.41           158.80      1956.0            0.1238   \n",
       "2          25.53           152.50      1709.0            0.1444   \n",
       "3          26.50            98.87       567.7            0.2098   \n",
       "4          16.67           152.20      1575.0            0.1374   \n",
       "\n",
       "   worst compactness  worst concavity  worst concave points  worst symmetry  \\\n",
       "0             0.6656           0.7119                0.2654          0.4601   \n",
       "1             0.1866           0.2416                0.1860          0.2750   \n",
       "2             0.4245           0.4504                0.2430          0.3613   \n",
       "3             0.8663           0.6869                0.2575          0.6638   \n",
       "4             0.2050           0.4000                0.1625          0.2364   \n",
       "\n",
       "   worst fractal dimension  \n",
       "0                  0.11890  \n",
       "1                  0.08902  \n",
       "2                  0.08758  \n",
       "3                  0.17300  \n",
       "4                  0.07678  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 555,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_feat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `target` key contains our labels (classes). Check it: you should see that it contains an array of 1s and 0s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 1 0 1 1 1 1 1 0 0 1 0 0 1 1 1 1 0 1 0 0 1 1 1 1 0 1 0 0\n",
      " 1 0 1 0 0 1 1 1 0 0 1 0 0 0 1 1 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 0 1 1 0 1 1\n",
      " 1 1 1 1 1 1 0 0 0 1 0 0 1 1 1 0 0 1 0 1 0 0 1 0 0 1 1 0 1 1 0 1 1 1 1 0 1\n",
      " 1 1 1 1 1 1 1 1 0 1 1 1 1 0 0 1 0 1 1 0 0 1 1 0 0 1 1 1 1 0 1 1 0 0 0 1 0\n",
      " 1 0 1 1 1 0 1 1 0 0 1 0 0 0 0 1 0 0 0 1 0 1 0 1 1 0 1 0 0 0 0 1 1 0 0 1 1\n",
      " 1 0 1 1 1 1 1 0 0 1 1 0 1 1 0 0 1 0 1 1 1 1 0 1 1 1 1 1 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 1 1 1 1 1 0 1 0 1 1 0 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 0 1 1 1 1 0 0 0 1 1\n",
      " 1 1 0 1 0 1 0 1 1 1 0 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 0\n",
      " 0 1 0 0 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 0 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1\n",
      " 1 0 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 1 0 1 1 1 1 1 0 1 1\n",
      " 0 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1\n",
      " 1 1 1 1 1 1 0 1 0 1 1 0 1 1 1 1 1 0 0 1 0 1 0 1 1 1 1 1 0 1 1 0 1 0 1 0 0\n",
      " 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 0 0 0 0 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "print(cancer['target'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store the target in a labels dataframe. Call it `df_target`. The data is the `target` key, and we can call the columns `Cancer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_target = pd.DataFrame(cancer['target'], columns=['Cancer'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print `df_target`. You shoud see a very simple dataframe containing 0s (and 1s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(df_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split\n",
    "\n",
    "Use `train_test_split` with `test_size=0.3` and `random_state=101`. We also want to convert our labels (`df_target`) from a column vector to a 1d array. Use the `np.ravel` function to do this! Do this when passing it as the `y` variable in `train_test_split`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df_feat\n",
    "y = np.ravel(df_target)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Support Vector Classifier\n",
    "\n",
    "`from sklearn.svm import SVC`. Then, create a new `SVC()` instance, and save it in `model`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "model = SVC()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the model to `X_train` and `y_train`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 561,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions and Evaluations\n",
    "\n",
    "Now let's predict using the trained model. Call `predict` on `X_test`, and print the `confusion_matrix` and the `classification_report`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0  66]\n",
      " [  0 105]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        66\n",
      "          1       0.61      1.00      0.76       105\n",
      "\n",
      "avg / total       0.38      0.61      0.47       171\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Steve/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(list(y_test), list(prediction)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Woah! You should see very low numbers: `0.38` for `precision`, `0.61` for `recall`, and `0.47` for `f1-score`. Notice that we are classifying everything into a single class (Class `1`)! This means our model needs to have it parameters adjusted (it may also help to normalize the data).\n",
    "\n",
    "We can search for parameters using a GridSearch!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GridsearchCV\n",
    "\n",
    "Finding the right parameters (like what `C` or `gamma` values to use) is a tricky task! But luckily, we can be a little lazy and just try a bunch of combinations and see what works best! This idea of creating a 'grid' of parameters and just trying out all the possible combinations is called a Gridsearch, this method is common enough that Scikit-learn has this functionality built in with GridSearchCV! The CV stands for cross-validation.\n",
    "\n",
    "GridSearchCV takes a dictionary that describes the parameters that should be tried and a model to train. The grid of parameters is defined as a dictionary, where the keys are the parameters and the values are the settings to be tested.  Use the following values for `param_grid`:\n",
    "* `'C': [0.1,1, 10, 100, 1000]`\n",
    "* `'gamma': [1,0.1,0.01,0.001,0.0001]`\n",
    "* `'kernel': ['rbf']`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 25 candidates, totalling 75 fits\n",
      "[CV] C=0.1, gamma=1 ..................................................\n",
      "[CV] .......... C=0.1, gamma=1, score=0.631578947368421, total=   0.0s\n",
      "[CV] C=0.1, gamma=1 ..................................................\n",
      "[CV] .......... C=0.1, gamma=1, score=0.631578947368421, total=   0.0s\n",
      "[CV] C=0.1, gamma=1 ..................................................\n",
      "[CV] ......... C=0.1, gamma=1, score=0.6363636363636364, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.1 ................................................\n",
      "[CV] ........ C=0.1, gamma=0.1, score=0.631578947368421, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.1 ................................................\n",
      "[CV] ........ C=0.1, gamma=0.1, score=0.631578947368421, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.1 ................................................\n",
      "[CV] ....... C=0.1, gamma=0.1, score=0.6363636363636364, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.01 ...............................................\n",
      "[CV] ....... C=0.1, gamma=0.01, score=0.631578947368421, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.01 ...............................................\n",
      "[CV] ....... C=0.1, gamma=0.01, score=0.631578947368421, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.01 ...............................................\n",
      "[CV] ...... C=0.1, gamma=0.01, score=0.6363636363636364, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.001 ..............................................\n",
      "[CV] ...... C=0.1, gamma=0.001, score=0.631578947368421, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.001 ..............................................\n",
      "[CV] ...... C=0.1, gamma=0.001, score=0.631578947368421, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.001 ..............................................\n",
      "[CV] ..... C=0.1, gamma=0.001, score=0.6363636363636364, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.0001 .............................................\n",
      "[CV] .... C=0.1, gamma=0.0001, score=0.9022556390977443, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.0001 .............................................\n",
      "[CV] .... C=0.1, gamma=0.0001, score=0.9624060150375939, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.0001 .............................................\n",
      "[CV] .... C=0.1, gamma=0.0001, score=0.9166666666666666, total=   0.0s\n",
      "[CV] C=1, gamma=1 ....................................................\n",
      "[CV] ............ C=1, gamma=1, score=0.631578947368421, total=   0.0s\n",
      "[CV] C=1, gamma=1 ....................................................\n",
      "[CV] ............ C=1, gamma=1, score=0.631578947368421, total=   0.0s\n",
      "[CV] C=1, gamma=1 ....................................................\n",
      "[CV] ........... C=1, gamma=1, score=0.6363636363636364, total=   0.0s\n",
      "[CV] C=1, gamma=0.1 ..................................................\n",
      "[CV] .......... C=1, gamma=0.1, score=0.631578947368421, total=   0.0s\n",
      "[CV] C=1, gamma=0.1 ..................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .......... C=1, gamma=0.1, score=0.631578947368421, total=   0.0s\n",
      "[CV] C=1, gamma=0.1 ..................................................\n",
      "[CV] ......... C=1, gamma=0.1, score=0.6363636363636364, total=   0.0s\n",
      "[CV] C=1, gamma=0.01 .................................................\n",
      "[CV] ......... C=1, gamma=0.01, score=0.631578947368421, total=   0.0s\n",
      "[CV] C=1, gamma=0.01 .................................................\n",
      "[CV] ......... C=1, gamma=0.01, score=0.631578947368421, total=   0.0s\n",
      "[CV] C=1, gamma=0.01 .................................................\n",
      "[CV] ........ C=1, gamma=0.01, score=0.6363636363636364, total=   0.0s\n",
      "[CV] C=1, gamma=0.001 ................................................\n",
      "[CV] ....... C=1, gamma=0.001, score=0.9022556390977443, total=   0.0s\n",
      "[CV] C=1, gamma=0.001 ................................................\n",
      "[CV] ....... C=1, gamma=0.001, score=0.9398496240601504, total=   0.0s\n",
      "[CV] C=1, gamma=0.001 ................................................\n",
      "[CV] ....... C=1, gamma=0.001, score=0.9545454545454546, total=   0.0s\n",
      "[CV] C=1, gamma=0.0001 ...............................................\n",
      "[CV] ...... C=1, gamma=0.0001, score=0.9398496240601504, total=   0.0s\n",
      "[CV] C=1, gamma=0.0001 ...............................................\n",
      "[CV] ...... C=1, gamma=0.0001, score=0.9699248120300752, total=   0.0s\n",
      "[CV] C=1, gamma=0.0001 ...............................................\n",
      "[CV] ....... C=1, gamma=0.0001, score=0.946969696969697, total=   0.0s\n",
      "[CV] C=10, gamma=1 ...................................................\n",
      "[CV] ........... C=10, gamma=1, score=0.631578947368421, total=   0.0s\n",
      "[CV] C=10, gamma=1 ...................................................\n",
      "[CV] ........... C=10, gamma=1, score=0.631578947368421, total=   0.0s\n",
      "[CV] C=10, gamma=1 ...................................................\n",
      "[CV] .......... C=10, gamma=1, score=0.6363636363636364, total=   0.0s\n",
      "[CV] C=10, gamma=0.1 .................................................\n",
      "[CV] ......... C=10, gamma=0.1, score=0.631578947368421, total=   0.0s\n",
      "[CV] C=10, gamma=0.1 .................................................\n",
      "[CV] ......... C=10, gamma=0.1, score=0.631578947368421, total=   0.0s\n",
      "[CV] C=10, gamma=0.1 .................................................\n",
      "[CV] ........ C=10, gamma=0.1, score=0.6363636363636364, total=   0.0s\n",
      "[CV] C=10, gamma=0.01 ................................................\n",
      "[CV] ........ C=10, gamma=0.01, score=0.631578947368421, total=   0.0s\n",
      "[CV] C=10, gamma=0.01 ................................................\n",
      "[CV] ........ C=10, gamma=0.01, score=0.631578947368421, total=   0.0s\n",
      "[CV] C=10, gamma=0.01 ................................................\n",
      "[CV] ....... C=10, gamma=0.01, score=0.6363636363636364, total=   0.0s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV] ...... C=10, gamma=0.001, score=0.8947368421052632, total=   0.0s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV] ...... C=10, gamma=0.001, score=0.9323308270676691, total=   0.0s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV] ...... C=10, gamma=0.001, score=0.9166666666666666, total=   0.0s\n",
      "[CV] C=10, gamma=0.0001 ..............................................\n",
      "[CV] ..... C=10, gamma=0.0001, score=0.9323308270676691, total=   0.0s\n",
      "[CV] C=10, gamma=0.0001 ..............................................\n",
      "[CV] ..... C=10, gamma=0.0001, score=0.9699248120300752, total=   0.0s\n",
      "[CV] C=10, gamma=0.0001 ..............................................\n",
      "[CV] ..... C=10, gamma=0.0001, score=0.9621212121212122, total=   0.0s\n",
      "[CV] C=100, gamma=1 ..................................................\n",
      "[CV] .......... C=100, gamma=1, score=0.631578947368421, total=   0.0s\n",
      "[CV] C=100, gamma=1 ..................................................\n",
      "[CV] .......... C=100, gamma=1, score=0.631578947368421, total=   0.0s\n",
      "[CV] C=100, gamma=1 ..................................................\n",
      "[CV] ......... C=100, gamma=1, score=0.6363636363636364, total=   0.0s\n",
      "[CV] C=100, gamma=0.1 ................................................\n",
      "[CV] ........ C=100, gamma=0.1, score=0.631578947368421, total=   0.0s\n",
      "[CV] C=100, gamma=0.1 ................................................\n",
      "[CV] ........ C=100, gamma=0.1, score=0.631578947368421, total=   0.0s\n",
      "[CV] C=100, gamma=0.1 ................................................\n",
      "[CV] ....... C=100, gamma=0.1, score=0.6363636363636364, total=   0.0s\n",
      "[CV] C=100, gamma=0.01 ...............................................\n",
      "[CV] ....... C=100, gamma=0.01, score=0.631578947368421, total=   0.0s\n",
      "[CV] C=100, gamma=0.01 ...............................................\n",
      "[CV] ....... C=100, gamma=0.01, score=0.631578947368421, total=   0.0s\n",
      "[CV] C=100, gamma=0.01 ...............................................\n",
      "[CV] ...... C=100, gamma=0.01, score=0.6363636363636364, total=   0.0s\n",
      "[CV] C=100, gamma=0.001 ..............................................\n",
      "[CV] ..... C=100, gamma=0.001, score=0.8947368421052632, total=   0.0s\n",
      "[CV] C=100, gamma=0.001 ..............................................\n",
      "[CV] ..... C=100, gamma=0.001, score=0.9323308270676691, total=   0.0s\n",
      "[CV] C=100, gamma=0.001 ..............................................\n",
      "[CV] ..... C=100, gamma=0.001, score=0.9166666666666666, total=   0.0s\n",
      "[CV] C=100, gamma=0.0001 .............................................\n",
      "[CV] .... C=100, gamma=0.0001, score=0.9172932330827067, total=   0.0s\n",
      "[CV] C=100, gamma=0.0001 .............................................\n",
      "[CV] .... C=100, gamma=0.0001, score=0.9774436090225563, total=   0.0s\n",
      "[CV] C=100, gamma=0.0001 .............................................\n",
      "[CV] .... C=100, gamma=0.0001, score=0.9393939393939394, total=   0.0s\n",
      "[CV] C=1000, gamma=1 .................................................\n",
      "[CV] ......... C=1000, gamma=1, score=0.631578947368421, total=   0.0s\n",
      "[CV] C=1000, gamma=1 .................................................\n",
      "[CV] ......... C=1000, gamma=1, score=0.631578947368421, total=   0.0s\n",
      "[CV] C=1000, gamma=1 .................................................\n",
      "[CV] ........ C=1000, gamma=1, score=0.6363636363636364, total=   0.0s\n",
      "[CV] C=1000, gamma=0.1 ...............................................\n",
      "[CV] ....... C=1000, gamma=0.1, score=0.631578947368421, total=   0.0s\n",
      "[CV] C=1000, gamma=0.1 ...............................................\n",
      "[CV] ....... C=1000, gamma=0.1, score=0.631578947368421, total=   0.0s\n",
      "[CV] C=1000, gamma=0.1 ...............................................\n",
      "[CV] ...... C=1000, gamma=0.1, score=0.6363636363636364, total=   0.0s\n",
      "[CV] C=1000, gamma=0.01 ..............................................\n",
      "[CV] ...... C=1000, gamma=0.01, score=0.631578947368421, total=   0.0s\n",
      "[CV] C=1000, gamma=0.01 ..............................................\n",
      "[CV] ...... C=1000, gamma=0.01, score=0.631578947368421, total=   0.0s\n",
      "[CV] C=1000, gamma=0.01 ..............................................\n",
      "[CV] ..... C=1000, gamma=0.01, score=0.6363636363636364, total=   0.0s\n",
      "[CV] C=1000, gamma=0.001 .............................................\n",
      "[CV] .... C=1000, gamma=0.001, score=0.8947368421052632, total=   0.0s\n",
      "[CV] C=1000, gamma=0.001 .............................................\n",
      "[CV] .... C=1000, gamma=0.001, score=0.9323308270676691, total=   0.0s\n",
      "[CV] C=1000, gamma=0.001 .............................................\n",
      "[CV] .... C=1000, gamma=0.001, score=0.9166666666666666, total=   0.0s\n",
      "[CV] C=1000, gamma=0.0001 ............................................\n",
      "[CV] ... C=1000, gamma=0.0001, score=0.9097744360902256, total=   0.0s\n",
      "[CV] C=1000, gamma=0.0001 ............................................\n",
      "[CV] ... C=1000, gamma=0.0001, score=0.9699248120300752, total=   0.0s\n",
      "[CV] C=1000, gamma=0.0001 ............................................\n",
      "[CV] ... C=1000, gamma=0.0001, score=0.9318181818181818, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  75 out of  75 | elapsed:    0.7s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'C': [0.1, 1, 10, 100, 1000], 'gamma': [1, 0.1, 0.01, 0.001, 0.0001]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=3)"
      ]
     },
     "execution_count": 567,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {'C': [0.1,1, 10, 100, 1000], 'gamma': [1,0.1,0.01,0.001,0.0001]}\n",
    "grid = GridSearchCV(model, param_grid, verbose = 3)\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the great things about GridSearchCV is that it is a meta-estimator. It takes an estimator like SVC, and creates a new estimator, that behaves exactly the same - in this case, like a classifier. You should add `refit=True` and choose verbose to whatever number you want (egs: `3`), higher the number, the more verbose (verbose just means the text output describing the process). `GridSearchCV` can be imported from `sklearn.model_selection`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 10, 'gamma': 0.0001}"
      ]
     },
     "execution_count": 568,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What fit does is a bit more involved then usual. First, it runs the same loop with cross-validation, to find the best parameter combination. Once it has the best combination, it runs fit again on all data passed to fit (without cross-validation), to built a single new model using the best parameter setting. Call `fit` on your `grid` object on `X_train` and `y_train`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_best = SVC(C=10, gamma = 0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can inspect the best parameters found by `GridSearchCV` in the `best_params_` attribute, and the best estimator in the `best_estimator_` attributes. Check them both...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=0.0001, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 570,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok! You should see that the new best parameters are `'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can re-run predictions on this grid object just like you would with a normal model. Run `predict` on `grid.best_estimator_` and then print the `confusion_matrix` and `classification_report` on these new predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_best = grid.best_estimator_.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 60   6]\n",
      " [  3 102]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, prediction_best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.91      0.93        66\n",
      "          1       0.94      0.97      0.96       105\n",
      "\n",
      "avg / total       0.95      0.95      0.95       171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(list(y_test), list(prediction_best)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see much better numbers! `0.95` for `precision`, `recall`, and `f1-score`. We used `GridSearchCV` to find the best parameter values for our Support Vector Classifier. Nice!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's look at the applications of machine learning techniques applied to health science and biomedical research. We'll use `RandomForestClassifier` and the Breast Cancer Wisconsin Dataset, downloaded from UC Irvine Machine Learning Repository (https://archive.ics.uci.edu/ml/datasets/breast+cancer+wisconsin+(original)).\n",
    "\n",
    "Read the `Breast_Cancer_dataset.csv` using `pd.read_csv`. Make sure to set `index_col='Id'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "metadata": {},
   "outputs": [],
   "source": [
    "bc_dataset = pd.read_csv('Breast_Cancer_dataset.csv', index_col='Id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the `head` to make sure your dataset looks good. You should see 9 features, and a label column called `Class`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Clump_Thickness</th>\n",
       "      <th>Uniformity_Cell_Size</th>\n",
       "      <th>Uniformity_Cell_Shape</th>\n",
       "      <th>Marginal_Adhesion</th>\n",
       "      <th>Single_Epithelial_Cell_Size</th>\n",
       "      <th>Bare_Nuclei</th>\n",
       "      <th>Bland_Chromatin</th>\n",
       "      <th>Normal_Nucleoli</th>\n",
       "      <th>Mitoses</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>431495</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324382</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1167471</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1213383</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1225382</th>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Clump_Thickness  Uniformity_Cell_Size  Uniformity_Cell_Shape  \\\n",
       "Id                                                                      \n",
       "431495                 3                     1                      1   \n",
       "324382                 1                     1                      1   \n",
       "1167471                4                     1                      2   \n",
       "1213383                5                     1                      1   \n",
       "1225382                6                     2                      3   \n",
       "\n",
       "         Marginal_Adhesion  Single_Epithelial_Cell_Size  Bare_Nuclei  \\\n",
       "Id                                                                     \n",
       "431495                   1                            2            1   \n",
       "324382                   1                            2            1   \n",
       "1167471                  1                            2            1   \n",
       "1213383                  4                            2            1   \n",
       "1225382                  1                            2            1   \n",
       "\n",
       "         Bland_Chromatin  Normal_Nucleoli  Mitoses  Class  \n",
       "Id                                                         \n",
       "431495                 3                2        1      2  \n",
       "324382                 2                1        1      2  \n",
       "1167471                3                1        1      2  \n",
       "1213383                3                1        1      2  \n",
       "1225382                1                1        1      2  "
      ]
     },
     "execution_count": 575,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bc_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create your feature dataframe (`df_features`) and label dataframes (`df_labels`): drop the `'Class'` column to create the features, and use the `'Class'` column as your labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features = bc_dataset.drop('Class', axis=1)\n",
    "df_labels = bc_dataset['Class']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `train_test_split` to split your data. Let's use `test_size=0.25` this time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_features\n",
    "y = df_labels\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the `shape` of your training and testing features and labels (`X_train`, `X_test`, `y_train`, `y_test`). You should have 9 features, with 358 training instances, and 120 test instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(358, 9)\n",
      "(120, 9)\n",
      "(358,)\n",
      "(120,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's build our `RandomForestClassifier` !  You can import it from `sklearn.ensemble`. Create an instance of it, call it `rfc`, and `fit` it to your training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 579,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, one cool thing about `RandomForestClassifier` is that, because of the way in which Random Forests work, they are able to assign an `importance` to every feature (which is exactly what it sounds like: a score / numerical value that represents how important every feature was, in coming up with the final decision). Let's take a look at the `feature_importances_` attribute.\n",
    "\n",
    "Create a DataFrame called `importances`. For your `data`, pass a dictionary object that contains 2 keys:\n",
    "* `'feature'`, which will be the features (i.e. the columns of your feature dataframe that you made earlier)\n",
    "* `'importance'`, which will be the `feature_importances_` attribute of your `RandomForestClassifier` object (`rfc`). Use `np.round` to set the number of decimal places to `3`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Clump_Thickness</td>\n",
       "      <td>0.060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Uniformity_Cell_Size</td>\n",
       "      <td>0.320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Uniformity_Cell_Shape</td>\n",
       "      <td>0.397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Marginal_Adhesion</td>\n",
       "      <td>0.016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Single_Epithelial_Cell_Size</td>\n",
       "      <td>0.034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Bare_Nuclei</td>\n",
       "      <td>0.117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Bland_Chromatin</td>\n",
       "      <td>0.032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Normal_Nucleoli</td>\n",
       "      <td>0.018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Mitoses</td>\n",
       "      <td>0.004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       feature  importance\n",
       "0              Clump_Thickness       0.060\n",
       "1         Uniformity_Cell_Size       0.320\n",
       "2        Uniformity_Cell_Shape       0.397\n",
       "3            Marginal_Adhesion       0.016\n",
       "4  Single_Epithelial_Cell_Size       0.034\n",
       "5                  Bare_Nuclei       0.117\n",
       "6              Bland_Chromatin       0.032\n",
       "7              Normal_Nucleoli       0.018\n",
       "8                      Mitoses       0.004"
      ]
     },
     "execution_count": 580,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary = {'feature':df_features.columns, 'importance': np.round(rfc.feature_importances_, decimals = 3)}\n",
    "importances = pd.DataFrame(dictionary)\n",
    "importances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, sort the importances dataframe in descending value. You can do this by calling `sort_values` on the dataframe, passing `ascending=False`, and `set_index` on the `feature` column. (If you're having trouble with this step, try Googling the `'sort_values'` and `'set_index'` pandas functions, and if you're stuck for more than 5-10 minutes, ask your instructor or TA :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = importances.sort_values(by='importance', ascending=False)\n",
    "importances = importances.set_index('feature')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, `print` the `importances`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             importance\n",
      "feature                                \n",
      "Uniformity_Cell_Shape             0.397\n",
      "Uniformity_Cell_Size              0.320\n",
      "Bare_Nuclei                       0.117\n",
      "Clump_Thickness                   0.060\n",
      "Single_Epithelial_Cell_Size       0.034\n",
      "Bland_Chromatin                   0.032\n",
      "Normal_Nucleoli                   0.018\n",
      "Marginal_Adhesion                 0.016\n",
      "Mitoses                           0.004\n"
     ]
    }
   ],
   "source": [
    "print(importances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see a list of features with their importances! Let's plot this in a very simple bar graph -- call `importances.plot.bar()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a260e9e10>"
      ]
     },
     "execution_count": 583,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a234ebfd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "importances.plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the bar graph and discuss your observations with your partner. Which features are most important, and which features are least important?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SelectFromModel\n",
    "\n",
    "`SelectFromModel` is quite simple -- it works by using a `threshold` to simply remove those features that are below the threshold. That's it! Let's do the following: use each of the feature importances that you printed above, as a threshold value. And for each one of those threshold values, create a `SelectFromModel` instance, call `fit` and `predict` on it, and find the `accuracy_score` for that prediction. What that means is that, we will be eliminating features one by one, and printing the accuracy each time.\n",
    "\n",
    "This part is pretty detailed, so we'll do it step by step.\n",
    "\n",
    "First, make the following imports:<br>\n",
    "`from numpy import sort\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_selection import SelectFromModel`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import sort\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_selection import SelectFromModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, create a `RandomForestClassifier`, `fit` it to the training data, and call `predict` on the test features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_final = rfc.predict(X_test)\n",
    "#print(prediction_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, call `accuracy_score` on your test data and your predictions. Print these scores using `np.round` and 2 decimal places."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.92"
      ]
     },
     "execution_count": 586,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(accuracy_score(y_test, prediction_final), decimals=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, now let's see how the accuracy changes with different thresholds that we pass to `SelectFromModel`.\n",
    "\n",
    "Create a `thresholds` array by calling `sort` on the `feature_importances_` of your RFC model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00381861, 0.0160021 , 0.01845125, 0.03213831, 0.03402399,\n",
       "       0.06033367, 0.11749089, 0.32040808, 0.39733309])"
      ]
     },
     "execution_count": 587,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thresholds = sort(rfc.feature_importances_)\n",
    "thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             importance\n",
      "feature                                \n",
      "Uniformity_Cell_Shape             0.397\n",
      "Uniformity_Cell_Size              0.320\n",
      "Bare_Nuclei                       0.117\n",
      "Clump_Thickness                   0.060\n",
      "Single_Epithelial_Cell_Size       0.034\n",
      "Bland_Chromatin                   0.032\n",
      "Normal_Nucleoli                   0.018\n",
      "Marginal_Adhesion                 0.016\n",
      "Mitoses                           0.004\n"
     ]
    }
   ],
   "source": [
    "print(importances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train.transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sfm_test = SelectFromModel(rfc, threshold=0.15)\n",
    "#sfm_test.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for feature_list_index in sfm_test.get_support(indices=True):\n",
    " #   print(df_features.columns[feature_list_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we are going to iterate through the `thresholds` array in a `for` loop. In each loop, we will do the following:\n",
    "1. Call `SelectFromModel` on our model, passing the current threshold. Make sure to pass `prefit=True` since our model has been already fit on our training data (`X_train`, `y_train`).\n",
    "2. Transform the training features by calling `.transform` on your training data (`X_train`). Store results in `select_X_train`.\n",
    "3. Create a new `RandomForestClassifier` model, and call `.fit` on it using your transformed training features from step 2. above (`select_X_train`). Note that you can pass the original training labels `y_train` (because we are only transforming the features!)\n",
    "4. Transform our test features (`X_test`) as well by calling `.transform` on them. Store results in `select_X_test`.\n",
    "5. Call `.predict` on our model created in step 3., passing our transformed test features from step 4 (`select_X_test`). Store the results in `predictions`.\n",
    "6. Get the `accuracy_score` between our predictions from step 5 (`predictions`) and our original test labels (`y_test`).\n",
    "7. Print the following information:\n",
    "    * The current threshold\n",
    "    * The reduced number of features used (you can get this from `shape[1]` of `select_X_train`).\n",
    "    * The accuracy for this reduced number of features (you got this in step 6.) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rfc = rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current threshold:  0.0038186093068719048\n",
      "how many features:  8\n",
      "accuracy score:  0.9583\n",
      "---\n",
      "current threshold:  0.01600210143312126\n",
      "how many features:  6\n",
      "accuracy score:  0.9583\n",
      "---\n",
      "current threshold:  0.018451254028669328\n",
      "how many features:  6\n",
      "accuracy score:  0.9333\n",
      "---\n",
      "current threshold:  0.03213830819625826\n",
      "how many features:  6\n",
      "accuracy score:  0.925\n",
      "---\n",
      "current threshold:  0.03402399295856124\n",
      "how many features:  6\n",
      "accuracy score:  0.925\n",
      "---\n",
      "current threshold:  0.06033367247633213\n",
      "how many features:  4\n",
      "accuracy score:  0.9417\n",
      "---\n",
      "current threshold:  0.1174908886525099\n",
      "how many features:  4\n",
      "accuracy score:  0.9417\n",
      "---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Steve/anaconda3/lib/python3.6/site-packages/sklearn/feature_selection/base.py:80: UserWarning: No features were selected: either the data is too noisy or the selection test too strict.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 feature(s) (shape=(358, 0)) while a minimum of 1 is required.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-606-449c1db53f0f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mselect_X_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msfm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mrfc_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mrfc_new\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mselect_X_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mselect_X_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msfm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrfc_new\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mselect_X_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    245\u001b[0m         \"\"\"\n\u001b[1;32m    246\u001b[0m         \u001b[0;31m# Validate or convert input data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csc\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    468\u001b[0m                              \u001b[0;34m\" a minimum of %d is required%s.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m                              % (n_features, shape_repr, ensure_min_features,\n\u001b[0;32m--> 470\u001b[0;31m                                 context))\n\u001b[0m\u001b[1;32m    471\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mwarn_on_dtype\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdtype_orig\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mdtype_orig\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found array with 0 feature(s) (shape=(358, 0)) while a minimum of 1 is required."
     ]
    }
   ],
   "source": [
    "for threshold in thresholds:\n",
    "    sfm = SelectFromModel(rfc, threshold=threshold, prefit=True)\n",
    "    select_X_train = sfm.transform(X_train)\n",
    "    rfc_new = RandomForestClassifier()\n",
    "    rfc_new.fit(select_X_train, y_train)\n",
    "    select_X_test = sfm.transform(X_test)\n",
    "    predictions = rfc_new.predict(select_X_test)\n",
    "    accuracy_score(y_test, predictions)\n",
    "    print('current threshold: ', threshold)\n",
    "    print('how many features: ', select_X_train.shape[1])\n",
    "    print('accuracy score: ', np.round(accuracy_score(y_test, predictions), decimals=4))\n",
    "    print('---')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SelectFromModel(estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "        norm_order=1, prefit=False, threshold=0.016)"
      ]
     },
     "execution_count": 607,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sfm_test = SelectFromModel(rfc, threshold=0.016)\n",
    "sfm_test.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clump_Thickness\n",
      "Uniformity_Cell_Size\n",
      "Uniformity_Cell_Shape\n",
      "Marginal_Adhesion\n",
      "Bare_Nuclei\n",
      "Bland_Chromatin\n"
     ]
    }
   ],
   "source": [
    "for feature_list_index in sfm_test.get_support(indices=True):\n",
    "    print(df_features.columns[feature_list_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using RFC, the optimal model (trade-off) is obtained with 6 features. A more complex model with 8 features would lead to similar accuracy, while a simpler model with only 2 features leads to a decrease in accuracy. These features are, in order of importance: Uniformity_Cell_Size, Bare_Nuclei, Uniformity_Cell_Shape, and Single_Epithelial_Cell_Size. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do you observe? Here is an example of the kind of analysis that you could write for Assignment 2:\n",
    "\n",
    "*\"In general, we observe the performance of the model decreases with the number of selected features. Using RFC, the optimal model (trade-off) is obtained with only 4 features. A more complex model with 7 features would lead to similar accuracy, while a simpler model with only 2 features leads to a decrease in accuracy. These features are, in order of importance Uniformity_Cell_Shape, Single_Epithelial_Cell_Size, Uniformity_cell_Size and Bare_Nuclei.\"*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recursive Feature Elimination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recursive Feature Elimination (or RFE) removes recursively features and builds a model on those features that remain. It uses the model estimated accuracy to identify which feature (or combination of features) contribute the most and rank them.\n",
    "\n",
    "Let's get a quick reminder of the features in order; print `df_features.columns`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Clump_Thickness', 'Uniformity_Cell_Size', 'Uniformity_Cell_Shape',\n",
      "       'Marginal_Adhesion', 'Single_Epithelial_Cell_Size', 'Bare_Nuclei',\n",
      "       'Bland_Chromatin', 'Normal_Nucleoli', 'Mitoses'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df_features.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, `from sklearn.feature_selection import RFE`, and create a new `RandomForestClassifier`. Call it `rfc`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "rfc = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's create an `RFE` model and try the best `4` features. Create an instance of `RFE` and pass it your model (`rfc`), and `4` for the number of features to keep. Call your `RFE` model `rfe_model`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfe_model = RFE(rfc, n_features_to_select=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, fit `rfe_model` to your training data (`X_train`, `y_train`). Make sure to assign the model back to the fit! (\n",
    "`rfe_model = rfe_model.fit(....)`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfe_model = rfe_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`print` the `support_` and `ranking_` attributes of your `rfe_model`.\n",
    "\n",
    "The `support_` attribute returns a boolean array of the feature indices that were chosen for your model from your original feature set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False  True  True False  True  True False False False]\n"
     ]
    }
   ],
   "source": [
    "print(rfe_model.support_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `ranking_` attribute shows you the rank for the features!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 1 1 4 1 1 5 3 6]\n",
      "Index(['Clump_Thickness', 'Uniformity_Cell_Size', 'Uniformity_Cell_Shape',\n",
      "       'Marginal_Adhesion', 'Single_Epithelial_Cell_Size', 'Bare_Nuclei',\n",
      "       'Bland_Chromatin', 'Normal_Nucleoli', 'Mitoses'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(rfe_model.ranking_)\n",
    "print(df_features.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's evaluate our new reduced feature set model on our test data! You can call `.predict` directly on your `rfe_model`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = rfe_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, `print` the `accuracy_score` on your `predictions`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Again, what do the `support`, `ranking`, and the `accuracy score` suggest? Again, here's a short example of what you could write for Assignment 2:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example\n",
    "*The top 4 features to be selected (i.e. valued as 1) for RFC model are â€˜Uniformity_Cell_Shapeâ€™, â€˜Uniformity_Cell_Sizeâ€™, â€˜Single_Epithelial_Cell_Sizeâ€™ and â€˜Bare_Nucleiâ€™. The performance of this model counting only 4 features leads to an estimated test accuracy of (some value) %*.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### My Analysis (based on current running) \n",
    "The top 4 features to be selected (i.e. valued as 1) for RFC model are 'Uniformity_Cell_Shape', 'Single_Epithelial_Cell_Size', 'Bare_Nuclei', and 'Uniformity_Cell_Size'. The performance of this model counting only 4 features leads to an estimated test accuracy of 93%. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Great job! Good luck on the Assignment, and let your instructor / TA know if you have any questions!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
